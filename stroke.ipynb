{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931533df",
   "metadata": {},
   "source": [
    "# Comparing 3 traditional classifiers\n",
    "\n",
    "In this notebook I will compare the performance of 3  \n",
    "traditional ML classifiers  \n",
    "* Logistic Regression\n",
    "* Gradient Boosting\n",
    "* Random Forests\n",
    "\n",
    "Perhaps in a future notebook I will include a Neural Net, but not here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62efda",
   "metadata": {},
   "source": [
    "## Data set\n",
    "The data set has 9 features on stroke patients and \n",
    "the target variable is whether the patient had a stroke.\n",
    "The data set can be found on Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "558ca2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77b29493",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv(\"full_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "189e9968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4981 entries, 0 to 4980\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             4981 non-null   object \n",
      " 1   age                4981 non-null   float64\n",
      " 2   hypertension       4981 non-null   int64  \n",
      " 3   heart_disease      4981 non-null   int64  \n",
      " 4   ever_married       4981 non-null   object \n",
      " 5   work_type          4981 non-null   object \n",
      " 6   Residence_type     4981 non-null   object \n",
      " 7   avg_glucose_level  4981 non-null   float64\n",
      " 8   bmi                4981 non-null   float64\n",
      " 9   smoking_status     4981 non-null   object \n",
      " 10  stroke             4981 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 428.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(orig_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5335a1",
   "metadata": {},
   "source": [
    "## Categorical variables\n",
    "Note that the data set has categorical variales.  \n",
    "I will used Pandas to do one hot encoding of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a8fe8742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hypertension  heart_disease  avg_glucose_level   bmi  stroke  \\\n",
       "0  67.0             0              1             228.69  36.6       1   \n",
       "1  80.0             0              1             105.92  32.5       1   \n",
       "\n",
       "   gender_Male  ever_married_Yes  work_type_Private  work_type_Self-employed  \\\n",
       "0            1                 1                  1                        0   \n",
       "1            1                 1                  1                        0   \n",
       "\n",
       "   work_type_children  Residence_type_Urban  smoking_status_formerly smoked  \\\n",
       "0                   0                     1                               1   \n",
       "1                   0                     0                               0   \n",
       "\n",
       "   smoking_status_never smoked  smoking_status_smokes  \n",
       "0                            0                      0  \n",
       "1                            1                      0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding of the categorical variables\n",
    "#  remove the originals from the new dataframe\n",
    "df = orig_df.copy()\n",
    "cat_cols = [idx for idx, val in df.dtypes.iteritems() if val == \"object\"]\n",
    "dummies = pd.get_dummies(df[cat_cols], drop_first=True)\n",
    "one_hot_cols = list(dummies.columns)\n",
    "df = pd.concat([orig_df, dummies], axis=1)\n",
    "df.drop(labels=cat_cols, axis=1, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ccbac32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target variable, i.e. the y column, and the x columns\n",
    "ycol =\"stroke\"\n",
    "num_cols = [x for x in df.columns if (x not in one_hot_cols) & (x != 'stroke')]\n",
    "xcols = one_hot_cols + num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00f9d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Pandas to partition off a test set\n",
    "idx = df.index\n",
    "test_size = int(np.floor(len(idx) * 0.1))\n",
    "test_idx = np.random.choice(idx, test_size)\n",
    "test = df.loc[test_idx]\n",
    "train_val = df.drop(test_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c90436dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn to partition train and test(really val)\n",
    "# we could use sklearn for test as well\n",
    "# but I find Pandas easer to use\n",
    "X = train_val[xcols]\n",
    "y = train_val[ycol]\n",
    "Xtest = test[xcols]\n",
    "ytest = test[ycol]\n",
    "val_size = 0.2\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=val_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "54f71865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X (3604, 14) y (3604,)\n",
      "val X (901, 14) y (901,)\n",
      "test X (498, 14) y (498,)\n"
     ]
    }
   ],
   "source": [
    "# define a dictional for the train, val and test sets, bot X and y for each\n",
    "# and check the size of each\n",
    "ds_dict = {\"train\" : (Xtrain, ytrain),\n",
    "            \"val\" : (Xval, yval),\n",
    "            \"test\": (Xtest, ytest)}\n",
    "for ds in ds_dict.keys():\n",
    "    X, y = ds_dict[ds]\n",
    "    print(f\"\"\"{ds} X {X.shape} y {y.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ab3bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create accuracy and loss\n",
    "# for each of the datasets given an input model\n",
    "def make_results(dsets, mod):\n",
    "    dfs = []\n",
    "    for name in dsets.keys():\n",
    "        X, y  = dsets[name]\n",
    "        rd = {}\n",
    "        ypred = mod.predict(X)\n",
    "        acc = accuracy_score(ypred, y.to_numpy().ravel())\n",
    "        proba = mod.predict_proba(X)\n",
    "        loss = log_loss(y.values, proba)\n",
    "        score = mod.score(X,y)\n",
    "        rd[\"acc\"] = acc\n",
    "        rd[\"loss\"] = loss\n",
    "        rdf = pd.DataFrame(rd, index=[0])\n",
    "        rdf[\"ds\"] = name\n",
    "        dfs.append(rdf)\n",
    "    res_df = pd.concat(dfs)    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "16277e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn throws lots of warnings, espicially with Logistic Regression\n",
    "# while not good practice in general, we will ignore the warnings\n",
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "#warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e784c1",
   "metadata": {},
   "source": [
    "## Hyperparameter search\n",
    "For all 3 methods we will use sklearn's GridSearchCV  \n",
    "to search over a grid of hyper parameters and   \n",
    "report on the results for the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa328d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_iter': 200, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950610</td>\n",
       "      <td>0.156825</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948946</td>\n",
       "      <td>0.173313</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.953815</td>\n",
       "      <td>0.135607</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc      loss     ds\n",
       "0  0.950610  0.156825  train\n",
       "0  0.948946  0.173313    val\n",
       "0  0.953815  0.135607   test"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {\n",
    "    \"penalty\": ['l1', 'l2', 'elasticnet' ],\n",
    "    \"solver\": [ \"lbfgs\", \"saga\" ],\n",
    "    \"max_iter\": [200, 400, 600],\n",
    "}\n",
    "start = datetime.datetime.now()\n",
    "grid_reg = GridSearchCV(\n",
    "    LogisticRegression(), param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    refit=True,\n",
    "    cv=5\n",
    ")\n",
    "regfit = grid_reg.fit(Xtrain, ytrain.to_numpy().ravel())\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(f\"search time {(end-start).total_seconds()}\")\n",
    "\n",
    "best_reg = regfit.best_estimator_\n",
    "reg_res = make_results(dsets, mod=best_reg)\n",
    "print(regfit.best_params_)\n",
    "reg_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce6a78",
   "metadata": {},
   "source": [
    "## Logistic results\n",
    "Note that the accuracy and loss are quit good for Logistic Regression  \n",
    "which is perhaps surprising since this is the least sophisticated method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "25fb4ca7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search time 132.604266\n",
      "{'learning_rate': 0.1, 'max_leaf_nodes': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950888</td>\n",
       "      <td>0.151802</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948946</td>\n",
       "      <td>0.168683</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.953815</td>\n",
       "      <td>0.136938</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc      loss     ds\n",
       "0  0.950888  0.151802  train\n",
       "0  0.948946  0.168683    val\n",
       "0  0.953815  0.136938   test"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 250, 500, 700 ],\n",
    "    \"max_leaf_nodes\": [3, 4, 6],\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "}\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "grid_gb = GridSearchCV(\n",
    "    GradientBoostingClassifier(), param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    refit=True,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "gfit = grid_gb.fit(Xtrain, ytrain.to_numpy().ravel())\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(f\"search time {(end-start).total_seconds()}\")\n",
    "\n",
    "best_gbm = gfit.best_estimator_\n",
    "gbm_res = make_results(dsets, mod=best_gbm)\n",
    "print(gfit.best_params_)\n",
    "gbm_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c03cc3",
   "metadata": {},
   "source": [
    "## Gradient Boosting results\n",
    "\n",
    "Here the results are very similar, with the main difference in  \n",
    "that the validation loss for GB is lower than for Logistic.   \n",
    "But this is not really a fair comparison since the valididation set\n",
    "is used in fitting with GB.\n",
    "\n",
    "Also note that it takes quit a bit longer to do the search for GB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "38eec6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search time 607.084353\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 50, 'oob_score': 'True'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.964761</td>\n",
       "      <td>0.094885</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958935</td>\n",
       "      <td>0.119844</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959839</td>\n",
       "      <td>0.104992</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc      loss     ds\n",
       "0  0.964761  0.094885  train\n",
       "0  0.958935  0.119844    val\n",
       "0  0.959839  0.104992   test"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 250, 500, ],\n",
    "    \"max_depth\": [2, 5, 10, 20],\n",
    "     \"min_samples_leaf\": [1, 3, 5],\n",
    "      \"oob_score\": [\"True\", \"False\"],\n",
    "    \"criterion\" : [\"gini\", \"entropy\", \"log_loss\"]\n",
    "    \n",
    "}\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(), param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    refit=True,\n",
    "    cv=5\n",
    ")\n",
    "rf_fit = grid_rf.fit(Xtrain, ytrain.to_numpy().ravel())\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(f\"search time {(end-start).total_seconds()}\")\n",
    "\n",
    "best_rf = rf_fit.best_estimator_\n",
    "rf_res = make_results(dsets, mod=best_rf)\n",
    "print(rf_fit.best_params_)\n",
    "rf_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fcf5e",
   "metadata": {},
   "source": [
    "## Random forest results\n",
    "Clearly better than the previous 2, but maybe not fair since we searched  \n",
    "over many more parameters.\n",
    "\n",
    "Still, impressive on the test loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boost",
   "language": "python",
   "name": "boost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
