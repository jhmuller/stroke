{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "931533df",
      "metadata": {
        "id": "931533df"
      },
      "source": [
        "# What\n",
        "Predict whether a patient will have a stroke,\n",
        "using features such as age, gender, whether they smoke, et cetera.  \n",
        "Also, compare the accuracy of predictions from \n",
        "3 common classifiers.\n",
        "\n",
        "# Why\n",
        "Knowing the probability of a future event\n",
        "can be valuable in many situations.\n",
        "For example, the event might be health related like a stroke.\n",
        "For a business the event could be whether a customer will leave,\n",
        " i.e. churn.\n",
        "The process and algorithms used here can apply \n",
        "to these and many other classification problems.\n",
        "\n",
        "# Background\n",
        "I wanted to compare results from some of the most widely used classification algorithms: \n",
        "* Logistic Regression,\n",
        "* Gradient Boosting, and\n",
        "* Random Forests.\n",
        "\n",
        "Note that comparison results from one data set\n",
        "should not be used for general conclusions.\n",
        "Clearly some data sets might be more amenable to one\n",
        "of the algorithms.\n",
        "\n",
        "I also wanted to use the hyperparameter \n",
        "tuning capabilities in sklearn."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c62efda",
      "metadata": {
        "id": "3c62efda"
      },
      "source": [
        "## Data set\n",
        "The data set has 9 features on stroke patients and \n",
        "the target variable is whether the patient had a stroke.\n",
        "The data set can be found on Kaggle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "558ca2f9",
      "metadata": {
        "id": "558ca2f9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77b29493",
      "metadata": {
        "id": "77b29493"
      },
      "outputs": [],
      "source": [
        "orig_df = pd.read_csv(\"full_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "189e9968",
      "metadata": {
        "id": "189e9968",
        "outputId": "65e3f107-2d4d-4d70-9f64-81ded60426c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4981 entries, 0 to 4980\n",
            "Data columns (total 11 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   gender             4981 non-null   object \n",
            " 1   age                4981 non-null   float64\n",
            " 2   hypertension       4981 non-null   int64  \n",
            " 3   heart_disease      4981 non-null   int64  \n",
            " 4   ever_married       4981 non-null   object \n",
            " 5   work_type          4981 non-null   object \n",
            " 6   Residence_type     4981 non-null   object \n",
            " 7   avg_glucose_level  4981 non-null   float64\n",
            " 8   bmi                4981 non-null   float64\n",
            " 9   smoking_status     4981 non-null   object \n",
            " 10  stroke             4981 non-null   int64  \n",
            "dtypes: float64(3), int64(3), object(5)\n",
            "memory usage: 428.2+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(orig_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5335a1",
      "metadata": {
        "id": "6d5335a1"
      },
      "source": [
        "## Categorical variables\n",
        "Note that the data set has categorical variales.  \n",
        "I will used Pandas to do one hot encoding of these variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8fe8742",
      "metadata": {
        "id": "a8fe8742",
        "outputId": "0e4fe944-c70f-4c30-fe60-2dc7208b7fa8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>stroke</th>\n",
              "      <th>gender_Male</th>\n",
              "      <th>ever_married_Yes</th>\n",
              "      <th>work_type_Private</th>\n",
              "      <th>work_type_Self-employed</th>\n",
              "      <th>work_type_children</th>\n",
              "      <th>Residence_type_Urban</th>\n",
              "      <th>smoking_status_formerly smoked</th>\n",
              "      <th>smoking_status_never smoked</th>\n",
              "      <th>smoking_status_smokes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  hypertension  heart_disease  avg_glucose_level   bmi  stroke  \\\n",
              "0  67.0             0              1             228.69  36.6       1   \n",
              "1  80.0             0              1             105.92  32.5       1   \n",
              "\n",
              "   gender_Male  ever_married_Yes  work_type_Private  work_type_Self-employed  \\\n",
              "0            1                 1                  1                        0   \n",
              "1            1                 1                  1                        0   \n",
              "\n",
              "   work_type_children  Residence_type_Urban  smoking_status_formerly smoked  \\\n",
              "0                   0                     1                               1   \n",
              "1                   0                     0                               0   \n",
              "\n",
              "   smoking_status_never smoked  smoking_status_smokes  \n",
              "0                            0                      0  \n",
              "1                            1                      0  "
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# one hot encoding of the categorical variables\n",
        "#  remove the originals from the new dataframe\n",
        "df = orig_df.copy()\n",
        "cat_cols = [idx for idx, val in df.dtypes.iteritems() if val == \"object\"]\n",
        "dummies = pd.get_dummies(df[cat_cols], drop_first=True)\n",
        "one_hot_cols = list(dummies.columns)\n",
        "df = pd.concat([orig_df, dummies], axis=1)\n",
        "df.drop(labels=cat_cols, axis=1, inplace=True)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccbac32e",
      "metadata": {
        "id": "ccbac32e"
      },
      "outputs": [],
      "source": [
        "# set the target variable, i.e. the y column, and the x columns\n",
        "ycol =\"stroke\"\n",
        "num_cols = [x for x in df.columns if (x not in one_hot_cols) & (x != 'stroke')]\n",
        "xcols = one_hot_cols + num_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the data set into train, test and val\n",
        "Below I use 2 methods to split a data set.\n",
        "1) Pandas/Numpy to split off the test set\n",
        "2) sklearn to split the remaining into test and val\n",
        "\n",
        "I used both for comparison.  \n",
        "Using sklearn is cleary easier since it is just a function call."
      ],
      "metadata": {
        "id": "D8-gY4y1gjKX"
      },
      "id": "D8-gY4y1gjKX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f9d6ff",
      "metadata": {
        "id": "00f9d6ff"
      },
      "outputs": [],
      "source": [
        "#use Pandas to partition off a test set\n",
        "idx = df.index\n",
        "test_size = int(np.floor(len(idx) * 0.1))\n",
        "test_idx = np.random.choice(idx, test_size)\n",
        "test = df.loc[test_idx]\n",
        "train_val = df.drop(test_idx, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c90436dd",
      "metadata": {
        "id": "c90436dd"
      },
      "outputs": [],
      "source": [
        "# use sklearn to partition train and test(really val)\n",
        "# we could use sklearn for test as well\n",
        "# but I find Pandas easer to use\n",
        "X = train_val[xcols]\n",
        "y = train_val[ycol]\n",
        "Xtest = test[xcols]\n",
        "ytest = test[ycol]\n",
        "val_size = 0.2\n",
        "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=val_size, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54f71865",
      "metadata": {
        "id": "54f71865",
        "outputId": "4d85f1b2-744b-496b-f515-7cb79691e2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train X (3604, 14) y (3604,)\n",
            "val X (901, 14) y (901,)\n",
            "test X (498, 14) y (498,)\n"
          ]
        }
      ],
      "source": [
        "# define a dictionary for the train, val and test sets, bot X and y for each\n",
        "# and check the size of each\n",
        "#  The dictionary will be handy in the make_results function below\n",
        "ds_dict = {\"train\" : (Xtrain, ytrain),\n",
        "            \"val\" : (Xval, yval),\n",
        "            \"test\": (Xtest, ytest)}\n",
        "for ds in ds_dict.keys():\n",
        "    X, y = ds_dict[ds]\n",
        "    print(f\"\"\"{ds} X {X.shape} y {y.shape}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab3bd52",
      "metadata": {
        "id": "9ab3bd52"
      },
      "outputs": [],
      "source": [
        "# define a function to create accuracy and loss\n",
        "# for each of the datasets given an input model\n",
        "def make_results(dsets, mod):\n",
        "    dfs = []\n",
        "    for name in dsets.keys():\n",
        "        X, y  = dsets[name]\n",
        "        rd = {}\n",
        "        ypred = mod.predict(X)\n",
        "        acc = accuracy_score(ypred, y.to_numpy().ravel())\n",
        "        proba = mod.predict_proba(X)\n",
        "        loss = log_loss(y.values, proba)\n",
        "        score = mod.score(X,y)\n",
        "        rd[\"acc\"] = acc\n",
        "        rd[\"loss\"] = loss\n",
        "        rdf = pd.DataFrame(rd, index=[0])\n",
        "        rdf[\"ds\"] = name\n",
        "        dfs.append(rdf)\n",
        "    res_df = pd.concat(dfs)    \n",
        "    return res_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16277e09",
      "metadata": {
        "id": "16277e09"
      },
      "outputs": [],
      "source": [
        "# sklearn throws lots of warnings, espicially with Logistic Regression\n",
        "# while not good practice in general, we will ignore the warnings\n",
        "import warnings\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "#warnings.warn = warn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80e784c1",
      "metadata": {
        "id": "80e784c1"
      },
      "source": [
        "## Hyperparameter search\n",
        "For all 3 methods we will use sklearn's GridSearchCV  \n",
        "to search over a grid of hyper parameters and   \n",
        "report on the results for the best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa328d7a",
      "metadata": {
        "id": "aa328d7a",
        "outputId": "e718145f-232f-4440-d404-5a5f67dad804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'max_iter': 200, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>ds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.950610</td>\n",
              "      <td>0.156825</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.948946</td>\n",
              "      <td>0.173313</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.953815</td>\n",
              "      <td>0.135607</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        acc      loss     ds\n",
              "0  0.950610  0.156825  train\n",
              "0  0.948946  0.173313    val\n",
              "0  0.953815  0.135607   test"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = {\n",
        "    \"penalty\": ['l1', 'l2', 'elasticnet' ],\n",
        "    \"solver\": [ \"lbfgs\", \"saga\" ],\n",
        "    \"max_iter\": [200, 400, 600],\n",
        "}\n",
        "start = datetime.datetime.now()\n",
        "grid_reg = GridSearchCV(\n",
        "    LogisticRegression(), param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    refit=True,\n",
        "    cv=5\n",
        ")\n",
        "regfit = grid_reg.fit(Xtrain, ytrain.to_numpy().ravel())\n",
        "\n",
        "end = datetime.datetime.now()\n",
        "print(f\"search time {(end-start).total_seconds()}\")\n",
        "\n",
        "best_reg = regfit.best_estimator_\n",
        "reg_res = make_results(dsets, mod=best_reg)\n",
        "print(regfit.best_params_)\n",
        "reg_res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58ce6a78",
      "metadata": {
        "id": "58ce6a78"
      },
      "source": [
        "## Logistic results\n",
        "Note that the accuracy and loss seem good for Logistic Regression  \n",
        "which is perhaps surprising since this is the least sophisticated method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25fb4ca7",
      "metadata": {
        "scrolled": false,
        "id": "25fb4ca7",
        "outputId": "6699549d-d178-481f-a41d-2af5f5769677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "search time 132.604266\n",
            "{'learning_rate': 0.1, 'max_leaf_nodes': 3, 'n_estimators': 50}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>ds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.950888</td>\n",
              "      <td>0.151802</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.948946</td>\n",
              "      <td>0.168683</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.953815</td>\n",
              "      <td>0.136938</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        acc      loss     ds\n",
              "0  0.950888  0.151802  train\n",
              "0  0.948946  0.168683    val\n",
              "0  0.953815  0.136938   test"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50, 100, 250, 500, 700 ],\n",
        "    \"max_leaf_nodes\": [3, 4, 6],\n",
        "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
        "}\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "grid_gb = GridSearchCV(\n",
        "    GradientBoostingClassifier(), param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    refit=True,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "gfit = grid_gb.fit(Xtrain, ytrain.to_numpy().ravel())\n",
        "\n",
        "end = datetime.datetime.now()\n",
        "print(f\"search time {(end-start).total_seconds()}\")\n",
        "\n",
        "best_gbm = gfit.best_estimator_\n",
        "gbm_res = make_results(dsets, mod=best_gbm)\n",
        "print(gfit.best_params_)\n",
        "gbm_res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28c03cc3",
      "metadata": {
        "id": "28c03cc3"
      },
      "source": [
        "## Gradient Boosting results\n",
        "\n",
        "Here the results are very similar, with the main difference in  \n",
        "that the validation loss for GB is lower than for Logistic.   \n",
        "But this is not really a fair comparison since the valididation set\n",
        "is used in fitting with GB.\n",
        "\n",
        "Also note that it takes quit a bit longer to do the search for GB but not in logistic regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38eec6d7",
      "metadata": {
        "id": "38eec6d7",
        "outputId": "eec8380d-df7e-4a5c-ea1c-cfefeb3bfaf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "search time 607.084353\n",
            "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 50, 'oob_score': 'True'}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>ds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.964761</td>\n",
              "      <td>0.094885</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.958935</td>\n",
              "      <td>0.119844</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.959839</td>\n",
              "      <td>0.104992</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        acc      loss     ds\n",
              "0  0.964761  0.094885  train\n",
              "0  0.958935  0.119844    val\n",
              "0  0.959839  0.104992   test"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50, 100, 250, 500, ],\n",
        "    \"max_depth\": [2, 5, 10, 20],\n",
        "     \"min_samples_leaf\": [1, 3, 5],\n",
        "      \"oob_score\": [\"True\", \"False\"],\n",
        "    \"criterion\" : [\"gini\", \"entropy\", \"log_loss\"]\n",
        "    \n",
        "}\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "grid_rf = GridSearchCV(\n",
        "    RandomForestClassifier(), param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    refit=True,\n",
        "    cv=5\n",
        ")\n",
        "rf_fit = grid_rf.fit(Xtrain, ytrain.to_numpy().ravel())\n",
        "\n",
        "end = datetime.datetime.now()\n",
        "print(f\"search time {(end-start).total_seconds()}\")\n",
        "\n",
        "best_rf = rf_fit.best_estimator_\n",
        "rf_res = make_results(dsets, mod=best_rf)\n",
        "print(rf_fit.best_params_)\n",
        "rf_res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e27fcf5e",
      "metadata": {
        "id": "e27fcf5e"
      },
      "source": [
        "## Random forest results\n",
        "Slightly better than the previous 2, but maybe not fair since we searched over many more parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "All 3 meethods seem to perform well with around 95% accuracy on the test set, but there is potentially room for improvement.  \n",
        "\n",
        "We do not have the luxury of collecting more data on the subjects, \n",
        "so our feature variables are fixed.\n",
        "\n",
        "We could try to create a new feature from some of the existing features, for example some kind of transform on the glocuse level.\n",
        "\n",
        "We could also try a completely different algorithm like a neural net.\n",
        "\n",
        "Both are good suggestions for a future project."
      ],
      "metadata": {
        "id": "OeGqX14TipMT"
      },
      "id": "OeGqX14TipMT"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BMjbjOx-kbnx"
      },
      "id": "BMjbjOx-kbnx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "boost",
      "language": "python",
      "name": "boost"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}